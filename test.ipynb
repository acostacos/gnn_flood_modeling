{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import time\n",
    "\n",
    "\n",
    "from models import GAT, GCN, SWEGNN\n",
    "from models.swe_gnn_ned import SWEGNN_NED\n",
    "from data import TemporalGraphDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "dataset, info = TemporalGraphDataset(node_features=config['node_features'],\n",
    "                    edge_features=config['edge_features'],\n",
    "                    **config['dataset_parameters']).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[1268, 6], edge_index=[2, 2612], edge_attr=[2612, 8], y=[1268, 1], pos=[2, 1268])\n",
      "<class 'torch.Tensor'> torch.Size([1268, 6])\n",
      "<class 'torch.Tensor'> torch.Size([2, 2612])\n",
      "<class 'torch.Tensor'> torch.Size([2612, 8])\n",
      "<class 'torch.Tensor'> torch.Size([1268, 1])\n",
      "{'num_static_node_features': 3, 'num_dynamic_node_features': 1, 'num_static_edge_features': 5, 'num_dynamic_edge_features': 1, 'previous_timesteps': 2}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])\n",
    "print(type(dataset[0].x), dataset[0].x.shape)\n",
    "print(type(dataset[0].edge_index), dataset[0].edge_index.shape)\n",
    "print(type(dataset[0].edge_attr), dataset[0].edge_attr.shape)\n",
    "print(type(dataset[0].y), dataset[0].y.shape)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = int(len(dataset) * 0.8) # 80% train, 20% test\n",
    "\n",
    "train_dataset = dataset[:num_train]\n",
    "# train_loader = DataLoader(train_dataset) # batch_size=32, shuffle=True\n",
    "\n",
    "test_dataset = dataset[num_train:]\n",
    "# test_loader = DataLoader(test_dataset) # batch_size=32, shuffle=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "base_model_params = {\n",
    "    'static_node_features': info['num_static_node_features'],\n",
    "    'dynamic_node_features': info['num_dynamic_node_features'],\n",
    "    'static_edge_features': info['num_static_edge_features'],\n",
    "    'dynamic_edge_features': info['num_dynamic_edge_features'],\n",
    "    'previous_timesteps': info['previous_timesteps'],\n",
    "    'device': device,\n",
    "}\n",
    "lr_info = config['training_parameters']\n",
    "model_info = config['model_parameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_func, optimizer):\n",
    "    start_time = time.time()\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for graph in train_dataset:\n",
    "            graph = graph.to(device)\n",
    "            labels = graph.y\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(graph)\n",
    "\n",
    "            loss = loss_func(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        epoch_loss = running_loss / num_train\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Training Loss: {epoch_loss:.4f}')\n",
    "    end_time = time.time()\n",
    "    print(f'Total training time: {end_time - start_time} seconds')\n",
    "\n",
    "\n",
    "def test(model, loss_func):\n",
    "    start_time = time.time()\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for graph in test_dataset:\n",
    "            graph = graph.to(device)\n",
    "            labels = graph.y\n",
    "\n",
    "            outputs = model(graph)\n",
    "\n",
    "            loss = loss_func(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Print validation statistics\n",
    "    print(f'Validation Loss: {running_loss:.4f}')\n",
    "    print(f'Inference time: {end_time - start_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 4.9178\n",
      "Epoch [2/10], Training Loss: 0.0215\n",
      "Epoch [3/10], Training Loss: 0.0206\n",
      "Epoch [4/10], Training Loss: 12.7546\n",
      "Epoch [5/10], Training Loss: 0.2981\n",
      "Epoch [6/10], Training Loss: 0.0434\n",
      "Epoch [7/10], Training Loss: 0.0298\n",
      "Epoch [8/10], Training Loss: 0.0277\n",
      "Epoch [9/10], Training Loss: 0.0260\n",
      "Epoch [10/10], Training Loss: 0.0237\n",
      "Total training time: 16.24303364753723 seconds\n"
     ]
    }
   ],
   "source": [
    "gcn_params = model_info['GCN']\n",
    "model = GCN(**gcn_params, **base_model_params)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr_info['learning_rate'], weight_decay=lr_info['weight_decay'])\n",
    "loss_func = torch.nn.L1Loss()\n",
    "\n",
    "train(model, loss_func, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.3263\n",
      "Inference time: 0.16010379791259766 seconds\n"
     ]
    }
   ],
   "source": [
    "test(model, loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 17.2771\n",
      "Epoch [2/10], Training Loss: 0.0395\n",
      "Epoch [3/10], Training Loss: 0.0230\n",
      "Epoch [4/10], Training Loss: 0.0215\n",
      "Epoch [5/10], Training Loss: 0.0209\n",
      "Epoch [6/10], Training Loss: 0.0412\n",
      "Epoch [7/10], Training Loss: 0.0208\n",
      "Epoch [8/10], Training Loss: 0.0208\n",
      "Epoch [9/10], Training Loss: 0.0210\n",
      "Epoch [10/10], Training Loss: 0.0213\n",
      "Total training time: 23.81217122077942 seconds\n"
     ]
    }
   ],
   "source": [
    "gat_params = model_info['GAT']\n",
    "model = GAT(**gat_params, **base_model_params)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr_info['learning_rate'], weight_decay=lr_info['weight_decay'])\n",
    "loss_func = torch.nn.L1Loss()\n",
    "\n",
    "train(model, loss_func, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2307\n",
      "Inference time: 0.26607489585876465 seconds\n"
     ]
    }
   ],
   "source": [
    "test(model, loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 0.0811\n",
      "Epoch [2/10], Training Loss: 0.0206\n",
      "Epoch [3/10], Training Loss: 0.0206\n",
      "Epoch [4/10], Training Loss: 0.0206\n",
      "Epoch [5/10], Training Loss: 0.0206\n",
      "Epoch [6/10], Training Loss: 0.0206\n",
      "Epoch [7/10], Training Loss: 0.0210\n",
      "Epoch [8/10], Training Loss: 0.1796\n",
      "Epoch [9/10], Training Loss: 0.0209\n",
      "Epoch [10/10], Training Loss: 0.0222\n",
      "Total training time: 162.76097869873047 seconds\n"
     ]
    }
   ],
   "source": [
    "swe_gnn_params = model_info['SWEGNN']\n",
    "model = SWEGNN(**swe_gnn_params, **base_model_params)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr_info['learning_rate'], weight_decay=lr_info['weight_decay'])\n",
    "loss_func = torch.nn.L1Loss()\n",
    "\n",
    "train(model, loss_func, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1828\n",
      "Inference time: 1.228783369064331 seconds\n"
     ]
    }
   ],
   "source": [
    "test(model, loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 7.0607\n",
      "Epoch [2/10], Training Loss: 0.0817\n",
      "Epoch [3/10], Training Loss: 0.0781\n",
      "Epoch [4/10], Training Loss: 0.0842\n",
      "Epoch [5/10], Training Loss: 0.0673\n",
      "Epoch [6/10], Training Loss: 0.0546\n",
      "Epoch [7/10], Training Loss: 0.0517\n",
      "Epoch [8/10], Training Loss: 0.0471\n",
      "Epoch [9/10], Training Loss: 0.0428\n",
      "Epoch [10/10], Training Loss: 0.0477\n",
      "Total training time: 127.4778802394867 seconds\n"
     ]
    }
   ],
   "source": [
    "# No encoder decoder\n",
    "swe_gnn_params = model_info['SWEGNN']\n",
    "swe_gnn_params['encoder_layers'] = 0\n",
    "swe_gnn_params['encoder_activation'] = None\n",
    "swe_gnn_params['decoder_layers'] = 0\n",
    "swe_gnn_params['decoder_activation'] = None\n",
    "\n",
    "model = SWEGNN(**swe_gnn_params, **base_model_params)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr_info['learning_rate'], weight_decay=lr_info['weight_decay'])\n",
    "loss_func = torch.nn.L1Loss()\n",
    "\n",
    "train(model, loss_func, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 3.2959\n",
      "Inference time: 1.157179594039917 seconds\n"
     ]
    }
   ],
   "source": [
    "test(model, loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Supervised Learning Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
