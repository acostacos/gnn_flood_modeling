{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import time\n",
    "\n",
    "\n",
    "from models import GAT, GCN, SWEGNN\n",
    "from models.swe_gnn_ned import SWEGNN_NED\n",
    "from data import TemporalGraphDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml') as f:\n",
    "    config = yaml.safe_load(f)\n",
    "\n",
    "dataset, info = TemporalGraphDataset(node_features=config['node_features'],\n",
    "                    edge_features=config['edge_features'],\n",
    "                    **config['dataset_parameters']).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data(x=[1268, 6], edge_index=[2, 2612], edge_attr=[2612, 8], y=[1268, 1], pos=[2, 1268])\n",
      "{'num_static_node_features': 3, 'num_dynamic_node_features': 1, 'num_static_edge_features': 5, 'num_dynamic_edge_features': 1, 'previous_timesteps': 2}\n"
     ]
    }
   ],
   "source": [
    "print(dataset[0])\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = int(len(dataset) * 0.8) # 80% train, 20% test\n",
    "\n",
    "train_dataset = dataset[:num_train]\n",
    "# train_loader = DataLoader(train_dataset) # batch_size=32, shuffle=True\n",
    "\n",
    "test_dataset = dataset[num_train:]\n",
    "# test_loader = DataLoader(test_dataset) # batch_size=32, shuffle=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "base_model_params = {\n",
    "    'static_node_features': info['num_static_node_features'],\n",
    "    'dynamic_node_features': info['num_dynamic_node_features'],\n",
    "    'static_edge_features': info['num_static_edge_features'],\n",
    "    'dynamic_edge_features': info['num_dynamic_edge_features'],\n",
    "    'previous_timesteps': info['previous_timesteps'],\n",
    "    'device': device,\n",
    "}\n",
    "lr_info = config['training_parameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loss_func, optimizer):\n",
    "    start_time = time.time()\n",
    "    num_epochs = 10\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for graph in train_dataset:\n",
    "            graph = graph.to(device)\n",
    "            labels = graph.y\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(graph)\n",
    "            loss = loss_func(outputs, labels)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / num_train\n",
    "        print(f'Epoch [{epoch + 1}/{num_epochs}], Training Loss: {epoch_loss:.4f}')\n",
    "    end_time = time.time()\n",
    "    print(f'Total training time: {end_time - start_time} seconds')\n",
    "\n",
    "\n",
    "def test(model, loss_func):\n",
    "    start_time = time.time()\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for graph in test_dataset:\n",
    "            graph = graph.to(device)\n",
    "            labels = graph.y\n",
    "\n",
    "            outputs = model(graph)\n",
    "            loss = loss_func(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Print validation statistics\n",
    "    print(f'Validation Loss: {running_loss:.4f}')\n",
    "    print(f'Inference time: {end_time - start_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 1.2887\n",
      "Epoch [2/10], Training Loss: 0.0256\n",
      "Epoch [3/10], Training Loss: 0.0227\n",
      "Epoch [4/10], Training Loss: 0.0211\n",
      "Epoch [5/10], Training Loss: 0.0210\n",
      "Epoch [6/10], Training Loss: 0.0213\n",
      "Epoch [7/10], Training Loss: 0.0208\n",
      "Epoch [8/10], Training Loss: 0.0208\n",
      "Epoch [9/10], Training Loss: 0.0203\n",
      "Epoch [10/10], Training Loss: 0.0200\n",
      "Total training time: 42.38818407058716 seconds\n"
     ]
    }
   ],
   "source": [
    "gcn_params = config['GCN']\n",
    "model = GCN(**gcn_params, **base_model_params)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr_info['learning_rate'], weight_decay=lr_info['weight_decay'])\n",
    "loss_func = torch.nn.L1Loss()\n",
    "\n",
    "train(model, loss_func, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.2097\n",
      "Inference time: 0.6375396251678467 seconds\n"
     ]
    }
   ],
   "source": [
    "test(model, loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 1.6340\n",
      "Epoch [2/10], Training Loss: 0.0280\n",
      "Epoch [3/10], Training Loss: 0.0269\n",
      "Epoch [4/10], Training Loss: 0.0315\n",
      "Epoch [5/10], Training Loss: 0.0221\n",
      "Epoch [6/10], Training Loss: 0.0215\n",
      "Epoch [7/10], Training Loss: 0.0522\n",
      "Epoch [8/10], Training Loss: 0.0214\n",
      "Epoch [9/10], Training Loss: 0.0206\n",
      "Epoch [10/10], Training Loss: 0.0206\n",
      "Total training time: 69.85159826278687 seconds\n"
     ]
    }
   ],
   "source": [
    "gat_params = config['GCN']\n",
    "model = GAT(**gat_params, **base_model_params)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr_info['learning_rate'], weight_decay=lr_info['weight_decay'])\n",
    "loss_func = torch.nn.L1Loss()\n",
    "\n",
    "train(model, loss_func, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1827\n",
      "Inference time: 0.7385728359222412 seconds\n"
     ]
    }
   ],
   "source": [
    "test(model, loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 0.0832\n",
      "Epoch [2/10], Training Loss: 0.0206\n",
      "Epoch [3/10], Training Loss: 0.0206\n",
      "Epoch [4/10], Training Loss: 0.0206\n",
      "Epoch [5/10], Training Loss: 0.0208\n",
      "Epoch [6/10], Training Loss: 0.0206\n",
      "Epoch [7/10], Training Loss: 0.0206\n",
      "Epoch [8/10], Training Loss: 0.0206\n",
      "Epoch [9/10], Training Loss: 0.0207\n",
      "Epoch [10/10], Training Loss: 0.0206\n",
      "Total training time: 184.67357468605042 seconds\n"
     ]
    }
   ],
   "source": [
    "swe_gnn_params = config['SWEGNN']\n",
    "model = SWEGNN(**swe_gnn_params, **base_model_params)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr_info['learning_rate'], weight_decay=lr_info['weight_decay'])\n",
    "loss_func = torch.nn.L1Loss()\n",
    "train(model, loss_func, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1828\n",
      "Inference time: 1.2828199863433838 seconds\n"
     ]
    }
   ],
   "source": [
    "test(model, loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 2.8461\n",
      "Epoch [2/10], Training Loss: 0.0378\n",
      "Epoch [3/10], Training Loss: 0.0400\n",
      "Epoch [4/10], Training Loss: 0.0330\n",
      "Epoch [5/10], Training Loss: 0.0319\n",
      "Epoch [6/10], Training Loss: 0.0281\n",
      "Epoch [7/10], Training Loss: 0.0237\n",
      "Epoch [8/10], Training Loss: 0.0228\n",
      "Epoch [9/10], Training Loss: 0.0210\n",
      "Epoch [10/10], Training Loss: 0.0208\n",
      "Total training time: 130.09719252586365 seconds\n"
     ]
    }
   ],
   "source": [
    "swe_gnn_params = config['SWEGNN']\n",
    "if 'hidden_features' in swe_gnn_params:\n",
    "    del swe_gnn_params['hidden_features']\n",
    "model = SWEGNN_NED(**swe_gnn_params, **base_model_params)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr_info['learning_rate'], weight_decay=lr_info['weight_decay'])\n",
    "loss_func = torch.nn.L1Loss()\n",
    "train(model, loss_func, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 0.1876\n",
      "Inference time: 1.0696780681610107 seconds\n"
     ]
    }
   ],
   "source": [
    "test(model, loss_func)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Supervised Learning Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
