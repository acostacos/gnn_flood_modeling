{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "from models import EdgeGNN, GAT, GCN, GraphSAGE, GIN, NodeEdgeGNN, SWEGNN\n",
    "from data import FloodingEventDataset\n",
    "from training import NodeRegressionTrainer, EdgeRegressionTrainer, DualRegressionTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1e9ff972ff0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('config.yaml') as f:\n",
    "    config = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from the following files:\n",
      "\tGraph Metadata Filepath:  data/graph_metadata.yaml\n",
      "\tFeature Metadata Filepath:  data/feature_metadata.yaml\n",
      "\tHEC-RAS HDF Filepath:  data/datasets/Model_01.p04.hdf\n",
      "\tNodes SHP Filepath:  data/datasets/geometry/cell_centers.shp\n",
      "\tEdges SHP Filepath:  data/datasets/geometry/links.shp\n",
      "Graph properties:\n",
      "\tTimesteps: 577\n",
      "\tEdge Index: torch.Size([2, 2612])\n",
      "\tPos: torch.Size([2, 1268])\n",
      "Successfully loaded for node_features:\n",
      "\tstatic (Shape: torch.Size([1268, 3])):\n",
      "\t\tarea: (1268,)\n",
      "\t\troughness: (1268,)\n",
      "\t\televation: (1268,)\n",
      "\tdynamic (Shape: torch.Size([577, 1268, 1])):\n",
      "\t\twater_level: (577, 1268)\n",
      "Successfully loaded for edge_features:\n",
      "\tstatic (Shape: torch.Size([2612, 5])):\n",
      "\t\tdirection_x: (2612,)\n",
      "\t\tdirection_y: (2612,)\n",
      "\t\tface_length: (2612,)\n",
      "\t\tlength: (2612,)\n",
      "\t\tslope: (2612,)\n",
      "\tdynamic (Shape: torch.Size([577, 2612, 1])):\n",
      "\t\tvelocity: (577, 2612)\n",
      "Expected node_features format:\n",
      "\t[\n",
      "\t\tarea (static)\n",
      "\t\troughness (static)\n",
      "\t\televation (static)\n",
      "\t\twater_level t-2 (dynamic)\n",
      "\t\twater_level t-1 (dynamic)\n",
      "\t\twater_level t (dynamic)\n",
      "\t]\n",
      "Expected edge_features format:\n",
      "\t[\n",
      "\t\tdirection_x (static)\n",
      "\t\tdirection_y (static)\n",
      "\t\tface_length (static)\n",
      "\t\tlength (static)\n",
      "\t\tslope (static)\n",
      "\t\tvelocity t-2 (dynamic)\n",
      "\t\tvelocity t-1 (dynamic)\n",
      "\t\tvelocity t (dynamic)\n",
      "\t]\n",
      "Succesfully loaded dateset.\n",
      "Number of data points:  576\n",
      "Sample data point:  Data(x=[1268, 6], edge_index=[2, 5224], edge_attr=[5224, 8], y=[1268, 1], pos=[2, 1268], y_edge=[5224, 1])\n",
      "Dataset Info:\n",
      "\tnum_static_node_features: 3\n",
      "\tnum_dynamic_node_features: 1\n",
      "\tnum_static_edge_features: 5\n",
      "\tnum_dynamic_edge_features: 1\n",
      "\tprevious_timesteps: 2\n"
     ]
    }
   ],
   "source": [
    "dataset, info = FloodingEventDataset(node_features=config['node_features'],\n",
    "                    edge_features=config['edge_features'],\n",
    "                    # debug=True,\n",
    "                    **config['dataset_parameters']).load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = int(len(dataset) * 0.8) # 80% train, 20% test\n",
    "\n",
    "train_dataset = dataset[:num_train]\n",
    "# train_loader = DataLoader(train_dataset) # batch_size=32, shuffle=True\n",
    "\n",
    "test_dataset = dataset[num_train:]\n",
    "# test_loader = DataLoader(test_dataset) # batch_size=32, shuffle=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "base_model_params = {\n",
    "    'static_node_features': info['num_static_node_features'],\n",
    "    'dynamic_node_features': info['num_dynamic_node_features'],\n",
    "    'static_edge_features': info['num_static_edge_features'],\n",
    "    'dynamic_edge_features': info['num_dynamic_edge_features'],\n",
    "    'previous_timesteps': info['previous_timesteps'],\n",
    "    'device': device,\n",
    "}\n",
    "lr_info = config['training_parameters']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node and Edge Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_edge_loss_func(node_pred, node_label, edge_pred, edge_label):\n",
    "    loss_func = torch.nn.L1Loss()\n",
    "    node_loss = loss_func(node_pred, node_label)\n",
    "    edge_loss = loss_func(edge_pred, edge_label)\n",
    "    return node_loss + edge_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 18.0119\n",
      "Epoch [2/10], Training Loss: 0.0626\n",
      "Epoch [3/10], Training Loss: 0.0626\n",
      "Epoch [4/10], Training Loss: 0.0623\n",
      "Epoch [5/10], Training Loss: 0.0620\n",
      "Epoch [6/10], Training Loss: 0.0615\n",
      "Epoch [7/10], Training Loss: 0.0612\n",
      "Epoch [8/10], Training Loss: 0.0601\n",
      "Epoch [9/10], Training Loss: 0.0588\n",
      "Epoch [10/10], Training Loss: 0.0575\n"
     ]
    }
   ],
   "source": [
    "model_params = config['model_parameters']['NodeEdgeGNN']\n",
    "model = NodeEdgeGNN(**model_params, **base_model_params)\n",
    "\n",
    "num_epochs = 10\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr_info['learning_rate'], weight_decay=lr_info['weight_decay'])\n",
    "loss_func = node_edge_loss_func\n",
    "\n",
    "trainer = DualRegressionTrainer(train_dataset=train_dataset, val_dataset=test_dataset, model=model,\n",
    "                                loss_func=loss_func, optimizer=optimizer, num_epochs=num_epochs, device=device)\n",
    "trainer.train()\n",
    "trainer.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training Loss: 0.0575\n",
      "Average training Loss: 1.8560\n",
      "Minimum training Loss: 0.0575\n",
      "Maximum training Loss: 18.0119\n",
      "Total training time: 33.0605 seconds\n",
      "Validation Loss: 0.0466\n",
      "Inference time: 0.261688 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = trainer.get_stats()\n",
    "stats.print_stats_summary()\n",
    "stats.plot_train_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Prediction Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_model_map = {\n",
    "    'SWEGNN': SWEGNN,\n",
    "    'GCN': GCN,\n",
    "    'GAT': GAT,\n",
    "    'GIN': GIN,\n",
    "    'GraphSAGE': GraphSAGE,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 44.1398\n",
      "Epoch [2/10], Training Loss: 0.0206\n",
      "Epoch [3/10], Training Loss: 0.0206\n",
      "Epoch [4/10], Training Loss: 0.0206\n",
      "Epoch [5/10], Training Loss: 0.0206\n",
      "Epoch [6/10], Training Loss: 0.0206\n",
      "Epoch [7/10], Training Loss: 0.0206\n",
      "Epoch [8/10], Training Loss: 0.0206\n",
      "Epoch [9/10], Training Loss: 0.0206\n",
      "Epoch [10/10], Training Loss: 0.0206\n"
     ]
    }
   ],
   "source": [
    "model_name = 'GIN' # Choose from the ff: SWEGNN, GCN, GAT, GIN, GraphSAGE\n",
    "model_params = config['model_parameters'][model_name]\n",
    "model = node_model_map[model_name](**model_params, **base_model_params)\n",
    "\n",
    "num_epochs = 10\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr_info['learning_rate'], weight_decay=lr_info['weight_decay'])\n",
    "loss_func = torch.nn.L1Loss()\n",
    "\n",
    "trainer = NodeRegressionTrainer(train_dataset=train_dataset, val_dataset=test_dataset, model=model,\n",
    "                                loss_func=loss_func, optimizer=optimizer, num_epochs=num_epochs, device=device)\n",
    "trainer.train()\n",
    "trainer.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training Loss: 0.0206\n",
      "Average training Loss: 4.4325\n",
      "Minimum training Loss: 0.0206\n",
      "Maximum training Loss: 44.1398\n",
      "Total training time: 6.3010 seconds\n",
      "Validation Loss: 0.0027\n",
      "Inference time: 0.082837 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "stats = trainer.get_stats()\n",
    "stats.print_stats_summary()\n",
    "stats.plot_train_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edge Prediction Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_model_map = {\n",
    "    'EdgeGNN': EdgeGNN,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Training Loss: 18.2951\n",
      "Epoch [2/10], Training Loss: 0.1546\n",
      "Epoch [3/10], Training Loss: 0.1536\n",
      "Epoch [4/10], Training Loss: 0.1537\n",
      "Epoch [5/10], Training Loss: 0.1536\n",
      "Epoch [6/10], Training Loss: 0.1536\n",
      "Epoch [7/10], Training Loss: 0.1536\n",
      "Epoch [8/10], Training Loss: 0.1535\n",
      "Epoch [9/10], Training Loss: 0.1535\n",
      "Epoch [10/10], Training Loss: 0.1535\n"
     ]
    }
   ],
   "source": [
    "model_name = 'EdgeGNN' # Choose from the ff: EdgeGNN\n",
    "model_params = config['model_parameters'][model_name]\n",
    "model = edge_model_map[model_name](**model_params, **base_model_params)\n",
    "\n",
    "num_epochs = 10\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr_info['learning_rate'], weight_decay=lr_info['weight_decay'])\n",
    "loss_func = torch.nn.L1Loss()\n",
    "\n",
    "trainer = EdgeRegressionTrainer(train_dataset=train_dataset, val_dataset=test_dataset, model=model,\n",
    "                                loss_func=loss_func, optimizer=optimizer, num_epochs=num_epochs, device=device)\n",
    "trainer.train()\n",
    "trainer.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = trainer.get_stats()\n",
    "stats.print_stats_summary()\n",
    "stats.plot_train_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Supervised Learning Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from models.graph_mae2 import GraphMAE2\n",
    "from utils.graph_mae2_utils import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "336\n",
      "Data(x=[1268, 6], edge_index=[2, 5224], edge_attr=[5224, 8], y=[1268, 1], pos=[2, 1268])\n",
      "<class 'torch.Tensor'> torch.Size([1268, 6])\n",
      "<class 'torch.Tensor'> torch.Size([2, 5224])\n",
      "<class 'torch.Tensor'> torch.Size([5224, 8])\n",
      "<class 'torch.Tensor'> torch.Size([1268, 1])\n",
      "{'num_static_node_features': 3, 'num_dynamic_node_features': 1, 'num_static_edge_features': 5, 'num_dynamic_edge_features': 1, 'previous_timesteps': 2}\n"
     ]
    }
   ],
   "source": [
    "dataset, info = FloodingEventDataset(node_features=config['node_features'],\n",
    "                    edge_features=config['edge_features'],\n",
    "                    **config['dataset_parameters']).load()\n",
    "\n",
    "print(len(dataset))\n",
    "print(dataset[0])\n",
    "print(type(dataset[0].x), dataset[0].x.shape)\n",
    "print(type(dataset[0].edge_index), dataset[0].edge_index.shape)\n",
    "print(type(dataset[0].edge_attr), dataset[0].edge_attr.shape)\n",
    "print(type(dataset[0].y), dataset[0].y.shape)\n",
    "print(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_train = int(len(dataset) * 0.8) # 80% train, 20% test\n",
    "\n",
    "train_dataset = dataset[:num_train]\n",
    "# train_loader = DataLoader(train_dataset) # batch_size=32, shuffle=True\n",
    "\n",
    "test_dataset = dataset[num_train:]\n",
    "# test_loader = DataLoader(test_dataset) # batch_size=32, shuffle=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "base_model_params = {\n",
    "    'static_node_features': info['num_static_node_features'],\n",
    "    'dynamic_node_features': info['num_dynamic_node_features'],\n",
    "    'static_edge_features': info['num_static_edge_features'],\n",
    "    'dynamic_edge_features': info['num_dynamic_edge_features'],\n",
    "    'previous_timesteps': info['previous_timesteps'],\n",
    "    'device': device,\n",
    "}\n",
    "lr_info = config['training_parameters']\n",
    "model_info = config['model_parameters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain(model, dataset, optimizer):\n",
    "    start_time = time.time()\n",
    "\n",
    "    max_epoch = 20\n",
    "    epoch_iter = tqdm(range(max_epoch))\n",
    "    model.to(device)\n",
    "    for epoch in epoch_iter:\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for graph in dataset:\n",
    "            graph = graph.to(device)\n",
    "            x = graph.x # Target\n",
    "            target_nodes = torch.arange(x.shape[0], device=device, dtype=torch.long)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            loss = model(graph, x, targets=target_nodes)\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        epoch_loss = running_loss / num_train\n",
    "        epoch_iter.set_description(f\"# Epoch {epoch}: train_loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f'Total pre-training time: {(end_time - start_time):4f} seconds')\n",
    "    return model\n",
    "\n",
    "def linear_probing(model, dataset, in_dim, out_dim, lr_f, weight_decay_f):\n",
    "    start_time = time.time()\n",
    "\n",
    "    decoder = LinearRegression(in_dim, out_dim).to(device)\n",
    "\n",
    "    num_finetune_params = [p.numel() for p in decoder.parameters() if  p.requires_grad]\n",
    "    print(f\"num parameters for finetuning: {sum(num_finetune_params)}\")\n",
    "\n",
    "    loss_f = torch.nn.MSELoss()\n",
    "    optimizer_f = torch.optim.Adam(decoder.parameters(), lr=lr_f, weight_decay=weight_decay_f)\n",
    "\n",
    "    best_model = None\n",
    "    max_epoch_f = 50\n",
    "    epoch_iter_f = tqdm(range(max_epoch_f))\n",
    "    model.eval()\n",
    "    decoder.train()\n",
    "    for epoch in epoch_iter_f:\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for graph in dataset:\n",
    "            optimizer_f.zero_grad()\n",
    "\n",
    "            graph = graph.to(device)\n",
    "            with torch.no_grad():\n",
    "                x = model.embed(graph)\n",
    "                x = x.to(device)\n",
    "            label = graph.y\n",
    "\n",
    "            out = decoder(x)\n",
    "            loss = loss_f(out, label)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer_f.step()\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        epoch_loss = running_loss / num_train\n",
    "        epoch_iter_f.set_description(f\"# Epoch {epoch}: train_loss: {epoch_loss:.4f}\")\n",
    "\n",
    "    end_time = time.time()\n",
    "    print(f'Final loss: {epoch_loss:4f}')\n",
    "    print(f'Total fine-tuning time: {(end_time - start_time):4f} seconds')\n",
    "\n",
    "    return decoder\n",
    "\n",
    "def test_ssl(model, ft_model, dataset, loss_func):\n",
    "    start_time = time.time()\n",
    "    model.eval()\n",
    "    ft_model.eval()\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for graph in dataset:\n",
    "            graph = graph.to(device)\n",
    "            x = model.embed(graph)\n",
    "            labels = graph.y\n",
    "\n",
    "            outputs = ft_model(x)\n",
    "\n",
    "            loss = loss_func(outputs, labels)\n",
    "            running_loss += loss.item()\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Print validation statistics\n",
    "    print(f'Validation Loss: {running_loss:.4f}')\n",
    "    print(f'Inference time: {end_time - start_time} seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Use sce_loss and alpha_l=3 ===\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Epoch 19: train_loss: 0.0224: 100%|| 20/20 [01:35<00:00,  4.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total pre-training time: 95.315137 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "graphmae2_params = model_info['GRAPHMAE2']\n",
    "in_dim = dataset[0].x.shape[1]\n",
    "model = GraphMAE2(in_dim=in_dim, **graphmae2_params)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr_info['learning_rate'], weight_decay=lr_info['weight_decay'])\n",
    "\n",
    "trained_model = pretrain(model, train_dataset, optimizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num parameters for finetuning: 2177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Epoch 49: train_loss: 620.0525: 100%|| 50/50 [00:56<00:00,  1.13s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final loss: 620.052530\n",
      "Total fine-tuning time: 56.627321 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "out_dim = dataset[0].y.shape[1]\n",
    "hidden_dim = graphmae2_params['num_hidden'] // graphmae2_params['nhead']\n",
    "ft_model = linear_probing(trained_model, train_dataset, hidden_dim, out_dim, 0.0008, lr_info['weight_decay'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Loss: 32728.5642\n",
      "Inference time: 0.2315971851348877 seconds\n"
     ]
    }
   ],
   "source": [
    "loss_func = torch.nn.L1Loss()\n",
    "test_ssl(trained_model, ft_model, test_dataset, loss_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbow\n",
      "num layer: 5 l1: 4 l2: 7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "====epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([12894, 6])\n",
      "torch.Size([12894, 1])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iteration:   0%|          | 0/2 [00:20<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "running_mean should contain 1 elements not 6",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[53], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodels\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgine\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpretrain_contextpred\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m main\n\u001b[0;32m      3\u001b[0m model_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels/gine/trained_model/gine_pretrain\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m----> 4\u001b[0m \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_file\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Carlo\\Documents\\School\\Masters\\NUS\\gnn_flood_modeling\\models\\gine\\pretrain_contextpred.py:162\u001b[0m, in \u001b[0;36mmain\u001b[1;34m(model_file)\u001b[0m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepochs\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m====epoch \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(epoch))\n\u001b[1;32m--> 162\u001b[0m     train_loss, train_acc \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_substruct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_substruct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28mprint\u001b[39m(train_loss, train_acc)\n\u001b[0;32m    165\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_model_file\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Carlo\\Documents\\School\\Masters\\NUS\\gnn_flood_modeling\\models\\gine\\pretrain_contextpred.py:43\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(args, model_substruct, model_context, loader, optimizer_substruct, optimizer_context, device)\u001b[0m\n\u001b[0;32m     40\u001b[0m batch \u001b[38;5;241m=\u001b[39m batch\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     42\u001b[0m \u001b[38;5;66;03m# creating substructure representation\u001b[39;00m\n\u001b[1;32m---> 43\u001b[0m substruct_rep \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_substruct\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_substruct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_index_substruct\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43medge_attr_substruct\u001b[49m\u001b[43m)\u001b[49m[batch\u001b[38;5;241m.\u001b[39mcenter_substruct_idx]\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m### creating context representations\u001b[39;00m\n\u001b[0;32m     46\u001b[0m overlapped_node_rep \u001b[38;5;241m=\u001b[39m model_context(batch\u001b[38;5;241m.\u001b[39mx_context, batch\u001b[38;5;241m.\u001b[39medge_index_context, batch\u001b[38;5;241m.\u001b[39medge_attr_context)[batch\u001b[38;5;241m.\u001b[39moverlap_context_substruct_idx]\n",
      "File \u001b[1;32mc:\\Users\\Carlo\\Documents\\School\\Masters\\NUS\\gnn_flood_modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Carlo\\Documents\\School\\Masters\\NUS\\gnn_flood_modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Carlo\\Documents\\School\\Masters\\NUS\\gnn_flood_modeling\\models\\gine\\model.py:71\u001b[0m, in \u001b[0;36mGINE.forward\u001b[1;34m(self, x, edge_index, edge_attr)\u001b[0m\n\u001b[0;32m     69\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgnns[layer](h_list[layer], edge_index, edge_attr)\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28mprint\u001b[39m(h\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m---> 71\u001b[0m h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norms\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlayer\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     72\u001b[0m \u001b[38;5;66;03m#h = F.dropout(F.relu(h), self.drop_ratio, training = self.training)\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m layer \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_layer \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     74\u001b[0m     \u001b[38;5;66;03m#remove relu for the last layer\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Carlo\\Documents\\School\\Masters\\NUS\\gnn_flood_modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Carlo\\Documents\\School\\Masters\\NUS\\gnn_flood_modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Carlo\\Documents\\School\\Masters\\NUS\\gnn_flood_modeling\\venv\\Lib\\site-packages\\torch\\nn\\modules\\batchnorm.py:193\u001b[0m, in \u001b[0;36m_BatchNorm.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    186\u001b[0m     bn_training \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_mean \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrunning_var \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m    188\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    189\u001b[0m \u001b[38;5;124;03mBuffers are only updated if they are to be tracked and we are in training mode. Thus they only need to be\u001b[39;00m\n\u001b[0;32m    190\u001b[0m \u001b[38;5;124;03mpassed when the update should occur (i.e. in training mode when they are tracked), or when buffer stats are\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \u001b[38;5;124;03mused for normalization (i.e. in eval mode when buffers are not None).\u001b[39;00m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 193\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    194\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    195\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# If buffers are not to be tracked, ensure that they won't be updated\u001b[39;49;00m\n\u001b[0;32m    196\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_mean\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrunning_var\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrack_running_stats\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    201\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    202\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbn_training\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    203\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexponential_average_factor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    205\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Carlo\\Documents\\School\\Masters\\NUS\\gnn_flood_modeling\\venv\\Lib\\site-packages\\torch\\nn\\functional.py:2812\u001b[0m, in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   2809\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training:\n\u001b[0;32m   2810\u001b[0m     _verify_batch_size(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39msize())\n\u001b[1;32m-> 2812\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_norm\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2813\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2814\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2815\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2816\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_mean\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2817\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrunning_var\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2818\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2819\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2820\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2821\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackends\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcudnn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menabled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2822\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: running_mean should contain 1 elements not 6"
     ]
    }
   ],
   "source": [
    "from models.gine.pretrain_contextpred import main\n",
    "\n",
    "model_file = 'models/gine/trained_model/gine_pretrain'\n",
    "main(model_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
